{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POPS_binary_extract-manual.ipynb <br>\n",
    "Author: Ricardo L. Pena <br>\n",
    "date: 9/14/2023 <br>\n",
    "Department of Chemistry <br>\n",
    "Colorado State University <br>\n",
    "penar@colostate.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import functions/modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import struct\n",
    "import time\n",
    "from itertools import chain\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import os\n",
    "import os.path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "## Binary Extraction Functions\n",
    "The functions listed below were provided by Dr. Rainwater at Handix Scientific. Permission was granted to me to use and publish the fast_flatten and extract_binary functions.\n",
    "* fast_flatten: Reduces or concatanates list of lists (list = [[member1 ],[member2 ],[member3 ],...]) into a single list (list = [member1, member2, member3, ...]).\n",
    "* extract_binary: extracts raw peak amplitudes and epoch timestamps from binary (.b) files and returns simple lists of the amplitudes and timestamps called PeakAmplitude and Timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### flatten list function\n",
    "def fast_flatten(input_list):\n",
    "    return list(chain.from_iterable(input_list))\n",
    "\n",
    "### extract binary function\n",
    "def extract_binary(binary_filename):\n",
    "    with open(binary_filename, mode='rb') as file: # b is important -> binary\n",
    "        fileContent = file.read()\n",
    "    lst = [fileContent]\n",
    "\n",
    "    file_length = len(fileContent) # full length of file\n",
    "    line_index_start = 0 # initialize the index to start at zero\n",
    "    list_peakamplitude, list_timestamps = [], [] # empty the lists\n",
    "\n",
    "    while file_length>line_index_start:\n",
    "        line_index_end = line_index_start+12 # do this here to not have to do it again\n",
    "        num_records, timestamp_val = struct.unpack('<Id',fileContent[line_index_start:line_index_end])\n",
    "        num_elements = num_records*3\n",
    "        line_record_end = line_index_end+(num_elements*4)\n",
    "\n",
    "        # get all the data out of the binary record here and into a numpy array\n",
    "        # might be a faster way to do this\n",
    "\n",
    "        chunk_data = struct.unpack('I'*num_elements,fileContent[line_index_end:line_record_end])\n",
    "        chunk_data = np.asarray(chunk_data).reshape(-1,3) # turn into an array and reshaped, could be done in a single step\n",
    "\n",
    "        # make an empty array to do the timestamp shenanigans\n",
    "        # dt = time between each record except for the first entry\n",
    "        # first dt is the time since the timestamp_val, float time\n",
    "\n",
    "        chunk_timestamp = np.empty(len(chunk_data),dtype='float64') # empty array with float precision\n",
    "        chunk_timestamp = np.cumsum(chunk_data[:,2]/1e6) # cumulative sum of the dt values, divide by 1e6 is because dt is in microseconds\n",
    "        chunk_timestamp += timestamp_val # adding the initial timestamp of the data record to get the true timestamp\n",
    "\n",
    "        # list comprehension is faster than numpy\n",
    "        chunk_timestamp = chunk_timestamp[:].tolist() # converting to list\n",
    "        chunk_amplitude = chunk_data[:,0].tolist() # converting to a list\n",
    "\n",
    "        # the two outputs PeakAmplitude and the Timestamp\n",
    "        # these are lists of lists\n",
    "        list_peakamplitude.append(chunk_amplitude)\n",
    "        list_timestamps.append(chunk_timestamp)\n",
    "        line_index_start = line_record_end # reset things\n",
    "\n",
    "    # at the end of this the lists of lists need flattening\n",
    "    t = time.time()\n",
    "    PeakAmplitude = fast_flatten(list_peakamplitude)\n",
    "    Timestamp = fast_flatten(list_timestamps)\n",
    "    elapsed = time.time() - t\n",
    "    del fileContent; del lst\n",
    "    return PeakAmplitude,Timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User input function\n",
    "* input_arguments: Enables and manages user inputs using the ArgumentParser module. This only works with python (.py) scripts and not jupyter notebooks (ipynb). Argument Parser turns a python script into a user interactive command line program that can record user inputs.\n",
    "\n",
    "    One of the user arguments is nbins which changes the number of bins we wish to bin the scatter peaks/counts into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_arguments(): # arguments that are user defined\n",
    "    # run script + -h to list current ports and see arguments.\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument('--directory', type = str,\n",
    "        help = 'Select the directory containing binary files or the directory containing subdirectories containing binaries.',\n",
    "        default=\".\")\n",
    "    parser.add_argument('--nbins', type = int,\n",
    "        help = 'Select the desired number of bins (default = 16 bins).',\n",
    "        default=16)\n",
    "    parser.add_argument('--mie', type = str,\n",
    "        help = 'Select the smoothed mie conversion table to interpolate bins from (default = Mie_scripps_1_41.csv).',\n",
    "        default='/Users/FarmerLab/Documents/python_scripts/mie_conversion_tables/Mie_scripps_1_41.csv')\n",
    "    parser.add_argument('--multiproc', action='store_true', help= 'call argument to enable binary processing with four processors.')\n",
    "    parser.add_argument('--logmin', type = float,\n",
    "        help = 'log of the amplitude corresponding to 120 nm in mie table (default = 0.871 for Scripps)',\n",
    "        default=0.871)\n",
    "    parser.add_argument('--logmax', type = float,\n",
    "        help = 'log of the amplitude corresponding to 3000 nm in mie table (default = 4.067 for Scripps)',\n",
    "        default=4.067)\n",
    "\n",
    "    arguments = parser.parse_args()\n",
    "    return arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mie Bin-Creation Functions\n",
    "* bin_headers: calculate the log amplitude bin edges based on a an equation provided in the POPS technical manual. The specific equation is log_bin_edge = logmin + ((logmax-logmin)/nbins)*bin_number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin set-up and convertion based on Mie conversion table\n",
    "def bin_headers(nbins, logmin, logmax):\n",
    "    #replicating mie conversion excel sheet sent by Dr. Bryan Rainwater at Handix\n",
    "    # The number of bins, logmin, and log max can change.\n",
    "    upper_bin_edge = []\n",
    "    lower_bin_edge = []\n",
    "    for i in range(0,nbins):\n",
    "        upper_n = i + 1\n",
    "        lower_n = i\n",
    "\n",
    "        l = logmin + ((logmax-logmin)/nbins)*lower_n\n",
    "        u = logmin + ((logmax-logmin)/nbins)*upper_n\n",
    "        # bin edges are reported as loggeed values; 10**bin_edge to get non-logged intensity/bin edges\n",
    "        lower_bin_edge.append(l)\n",
    "        upper_bin_edge.append(u)\n",
    "    return lower_bin_edge, upper_bin_edge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* linear_interpolation: use the linear slope between two points to find the y value of a given x value between the two points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_interpolation(x_lower,y_lower,x_upper,y_upper,x_interp, logged):\n",
    "    if logged == True: np.log10(x_interp)\n",
    "    y_interp = y_lower + ((x_interp - x_lower)*((y_upper-y_lower)/(x_upper-x_lower)))\n",
    "    return y_interp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* intensity_2_diameter: convert bin edges listed as raw amplitudes to nm particle diameters given a mie conversion table to account for varying index of refraction.\n",
    "\n",
    "    for each amplitude bin edge:\n",
    "    1. Check if the provided mie conversion table lists logged amplitudes or raw amplitudes. We assume that Log_Intensity is false which means that our mie conversion table lists raw peak amplitudes/intensities. As a result, we take the log10 of our mie table amplitudes such that we can directly compare to our logged bin edges yielded by the bin_headers function.\n",
    "     - if the mie table already displays logged amplitudes, then we use the table as is.\n",
    "    2. Scan through each of the mie table amplitudes (IOR_raw_amp) and see which amplitudes encompass our bin edge. We start scanning mie amplitudes from smallest to largest such that for a bin edge located somewhere in the middle of our amplitude range, the bin edge amplitude is greater than our mie amplitudes. Thus, the initial bottom and top bools are True and False. When we get to mie amplitudes greater than our bin edge, the bools switch to become False and True for bottom and top. The mie table amplitude for-loop breaks (stops) at the first instance where the bools switch. The break index is recorded as the index of the upper mie amplitude and the index-1 is recorded for the lower mie amplitude. \n",
    "    3. These indices are then used to identify the mie table amplitudes that surround the bin edge along with the upper and lower diameters that correspond to the upper and lower mie amplitudes we identified.\n",
    "    4. The bin edge is converted from a logged value back to a normal by setting the bin edge as the exponent of 10.\n",
    "    5. Then, using the upper and lower amplitudes and diameters, we can linearly interpolate a diamter for our amplitude bin edge.\n",
    "    6. The bin edge and its interpolated diameter are recorded to the raw amplitudes and interp_diameter lists.\n",
    "    7. the above steps are repeated for the next bin edge in our list of bin edges from the bin_headers function.\n",
    "\n",
    "<center><img src=\"IMG_2433.jpg\" alt=\"Intensity_2_diameter\" width=\"25%\" height=\"auto\" class=\"blog-image\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def itensity_2_diameter(bin_range, Mie_map_amp, Mie_map_diam, Log_Intensity):\n",
    "    raw_amplitude, interp_diameter = [], []\n",
    "    for signal_amp in bin_range:\n",
    "        try:\n",
    "            IOR_raw_amp = np.log10(Mie_map_amp) # immediately take log to compare to logged bin edges(signal_amp)\n",
    "            # bool = is amp value in mie table the log intensity of the amplitude or the raw amplitude?\n",
    "            # True indicates that the mie table displays logged amplitudes or intensities.\n",
    "            # False indicates that raw amplitudes/intensities are displayed in conversion table.\n",
    "            if Log_Intensity == True: IOR_raw_amp = Mie_map_amp\n",
    "\n",
    "            for i, amp in enumerate(IOR_raw_amp):\n",
    "                    bottom = bool(signal_amp >= amp)\n",
    "                    top = bool(signal_amp <=amp)\n",
    "\n",
    "                    if ((bottom == False) and (top == True)):\n",
    "                        upper_idx = i\n",
    "                        lower_idx = i-1\n",
    "                        break\n",
    "            upper_amp, lower_amp =  Mie_map_amp[upper_idx], Mie_map_amp[lower_idx]\n",
    "            upper_diam, lower_diam = Mie_map_diam[upper_idx], Mie_map_diam[lower_idx]\n",
    "\n",
    "            # x is amp and y is diameter\n",
    "            #if Log_Intensity == False: signal_amp = 10**signal\n",
    "            signal = 10**signal_amp #the signal_amp is always logged, but log needs to be undone to correctly bin raw intensities which are not logged.\n",
    "            signal_diam = linear_interpolation(lower_amp, lower_diam, upper_amp, upper_diam, signal, Log_Intensity)\n",
    "            raw_amplitude.append(signal)\n",
    "            interp_diameter.append(signal_diam)\n",
    "            #print(signal, signal_diam)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"outside of Mie amp range\")\n",
    "            print(e)\n",
    "    return raw_amplitude, interp_diameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* create_bins: Returns a mie table containing bin edge amplitudes, bin edge diameter, the mean bin diameter, and header labels.\n",
    "\n",
    "    mie table:\n",
    "    1. Calculated bin edges (intensity) and their corresponding diameters are curated into a table. The lower bin edges are added to a column called \"Lower Amp\" while the upper bin edges are added to a column called \"Upper Amp\". The interpolated bin edges for the upper and lower amplitudes are labeled \"Lower Bin Diameter\" and \"Upper Bin Diameter\" in the table. \n",
    "    2. The center (mean) bin diameter is calculated and added to a column in the dataframe called \"Mean Diameter (nm)\". \n",
    "    3. The diameter bin edges are concatenated togther in a string to be used a table headers. The strings are placed in the \"Bin Header\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate log intensity bin edges for desired bin number\n",
    "def create_bins(nbins,logmin,logmax, mie_conv_table_intensity, mie_conv_table_diam, logged_amplitudes):\n",
    "    l_bin, u_bin = bin_headers(nbins, logmin, logmax)\n",
    "\n",
    "    upper_raw_amp, upper_interp_diam = itensity_2_diameter(u_bin,mie_conv_table_intensity, mie_conv_table_diam, logged_amplitudes)\n",
    "    lower_raw_amp, lower_interp_diam = itensity_2_diameter(l_bin, mie_conv_table_intensity, mie_conv_table_diam,logged_amplitudes)\n",
    "    mie_smooth_dict = {\"Lower Amp\": lower_raw_amp, \"Upper Amp\": upper_raw_amp,\n",
    "                \"Lower Bin Diameter\": lower_interp_diam, \"Upper Bin Diameter\": upper_interp_diam}\n",
    "    mie_smooth_df = pd.DataFrame(mie_smooth_dict)\n",
    "    mie_smooth_df['Mean Diameter (nm)'] = mie_smooth_df[['Lower Bin Diameter','Upper Bin Diameter']].mean(axis=1)\n",
    "    mie_smooth_df['Bin Header'] = round(mie_smooth_df['Lower Bin Diameter'],2).astype('str') + \"_\" + round(mie_smooth_df['Upper Bin Diameter'],2).astype('str')\n",
    "    return mie_smooth_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Code\n",
    "## Main working functions\n",
    "* binary_2_csv: Produces a 10 Hz, 30-minute binned counts file from a singular binary file containing raw peak amplitudes and epoch times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Main working functions\n",
    "def binary_2_csv(binary_mie_bins_info): # main working function\n",
    "    # retrieve binary file to process and the bins and mie table to use\n",
    "    binary_file = binary_mie_bins_info[0]\n",
    "    mie_table = binary_mie_bins_info[1]\n",
    "    bins = binary_mie_bins_info[2]\n",
    "\n",
    "    file_csv_name = binary_file.split('.b')[0]+'_10Hz.csv'\n",
    "    ### check if file already exists before extracting the binary again ###\n",
    "    if (os.path.isfile(file_csv_name) == False):\n",
    "        print('created {}'.format(file_csv_name))\n",
    "        peaks, time_s = extract_binary(binary_file)\n",
    "\n",
    "        # (1) create a raw dataframe from binary data\n",
    "        raw_peak_df = pd.DataFrame({'timestamp': time_s,'Peaks':peaks}) #.to_csv(file_csv_name)\n",
    "        #raw_peak_df.to_csv(binary_file.split('.b')[0]+'_raw.csv') ### binning check!\n",
    "        raw_peak_df['timestamp'] = raw_peak_df['timestamp'].apply(lambda x: datetime.utcfromtimestamp(x)) #recently updated\n",
    "        timing_df = raw_peak_df.set_index('timestamp') # set timestamp as index\n",
    "\n",
    "        # (2) resampling the data to 10Hz\n",
    "        try:\n",
    "            df_10Hz = timing_df.groupby(pd.Grouper(freq='100ms'))['Peaks'].apply(list)\n",
    "            #df_10Hz.to_csv(binary_file.split('.b')[0]+'_grouped-10Hz.csv') ### binning check!\n",
    "            # bin and count the data now\n",
    "            bin_counts = df_10Hz.apply(lambda x: pd.cut(x, bins=bins).value_counts())\n",
    "            bin_counts.columns = mie_table['Bin Header']\n",
    "            bin_counts.to_csv(file_csv_name)\n",
    "\n",
    "            ### added in these lines to visualize df's created in steps 1 and 2\n",
    "            return raw_peak_df, df_10Hz, bin_counts\n",
    "\n",
    "            lst_p = [peaks, time_s, raw_peak_df, timing_df, df_10Hz, bin_counts]\n",
    "            del peaks; del time_s; del raw_peak_df; del timing_df; del df_10Hz; del bin_counts\n",
    "            del lst_p\n",
    "        except: print(\"Fatal error in file: \",file_csv_name)\n",
    "\n",
    "    else:\n",
    "        print ('{} already exists!'.format(file_csv_name))\n",
    "        pass\n",
    "\n",
    "    lst = [binary_file, mie_table, bins]\n",
    "    del binary_file; del mie_table; del bins\n",
    "    del lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* main: Gathes the user input information to develope the desired number of bins and bin labels from a provided mie table. The bins are used then for processing with binary_2_csv provided that the 10Hz file doesn;t exist already. Multiple binary files can be processed at the same time with multiproc or individualy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    ### User defined arguments\n",
    "    num_bins = args.nbins #16 # turn into arg\n",
    "    logmin = args.logmin\n",
    "    logmax = args.logmax\n",
    "    mie_input_csv = args.mie\n",
    "    working_dir = args.directory\n",
    "    run_multiprocessing = args.multiproc\n",
    "\n",
    "    ### define Mie Table based on num bins:\n",
    "    # logmin and logmax change depending on the mie table used.\n",
    "    # look at the amplitude for 120 nm and 3000 nm and take log10 of amplitude\n",
    "    \n",
    "    #\"Scripps:\n",
    "    # logmin = 0.871; 120 nm\n",
    "    # logmax = 4.067; 3000 nm\"\n",
    " \n",
    "    # \"chestnutridge\n",
    "    # logmin = 1.526; 120 nm\n",
    "    # logmax = 4.562; 3000nm\"\n",
    "\n",
    "\n",
    "    # also turn mie conversion table into arg\n",
    "    mie_conv_table = pd.read_csv(mie_input_csv)\n",
    "    table_amp = mie_conv_table['amp_scale']\n",
    "    table_diam = mie_conv_table['d_nm']\n",
    "    mie_table = create_bins(num_bins,logmin,logmax,table_amp, table_diam, False)\n",
    "    mie_table.to_csv(working_dir+\"/resulting_mie-table.csv\") ### binning check!\n",
    "    bins = (list(mie_table['Lower Amp'])\n",
    "    + list(mie_table['Upper Amp'][-1:]))\n",
    "\n",
    "    ### Walk subdirectories for all binary files ###\n",
    "    source_directory = working_dir\n",
    "    # create list of binary files with complete path included\n",
    "    binary_files_2_process = []\n",
    "    for dirpath, dirnames, filenames in os.walk(source_directory):\n",
    "        for filename in [f for f in filenames if f.endswith(\".b\")]:\n",
    "            full_path = os.path.join(dirpath, filename)\n",
    "            binary_files_2_process.append(full_path)\n",
    "    binary_files_2_process.sort(key=os.path.getmtime)\n",
    "\n",
    "    print('Extracting POPS binaries...')\n",
    "    binary_mie_bins = [(f, mie_table, bins) for f in binary_files_2_process] # single arg for pool\n",
    "\n",
    "    ### Perform extraction is pools of 4 (four processes at once) ###\n",
    "    if run_multiprocessing == True:\n",
    "        print('Multiprocessing enabled... 4 procs being used.')\n",
    "        p = Pool(4)\n",
    "        p.map(binary_2_csv,binary_mie_bins)\n",
    "    else:\n",
    "        for group in binary_mie_bins:\n",
    "            try:\n",
    "                binary_2_csv(group) # Main function that produces binned count csv's\n",
    "            except Exception as e:\n",
    "                print(\"File Error!\")\n",
    "                print(\"{} failed\".format(group))\n",
    "                print(\"error:\\n\", e)\n",
    "    print('done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Python Executable\n",
    "execute the main functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Execute everything as a python script\n",
    "# if __name__ == '__main__':\n",
    "#     args = input_arguments()\n",
    "#     main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the code\n",
    "Delete the Peak_*_10Hz.csv's prior to running this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hard coded arguments\n",
    "# num_bins = args.nbins #16 # turn into arg\n",
    "# logmin = args.logmin\n",
    "# logmax = args.logmax\n",
    "# mie_input_csv = args.mie\n",
    "# working_dir = args.directory\n",
    "# run_multiprocessing = args.multiproc\n",
    "\n",
    "num_bins = 16\n",
    "logmin = 0.871\n",
    "logmax = 4.067\n",
    "mie_input_csv = '../mie_conversion_tables/Mie_scripps_1_41.csv'\n",
    "working_dir = './Example_data/POPS_F20230707/'\n",
    "\n",
    "# keep false when running in jupyter notebook. Some additions have been made to \n",
    "# this code to visualize data in jupyter lab/notebook. Use the original code if\n",
    "# you desire to run the python executable.\n",
    "run_multiprocessing = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of bin edges reported as raw intensities:\n",
      "7.430191378967014\n",
      "11.769282841042024\n",
      "18.64232178252499\n",
      "29.52908568322213\n",
      "46.77351412871981\n",
      "74.08836316231077\n",
      "117.35456824912899\n",
      "185.88742011708283\n",
      "294.4421633798763\n",
      "466.3908268844408\n",
      "738.7542629936365\n",
      "1170.1728027907702\n",
      "1853.5316234148124\n",
      "2935.9590915163635\n",
      "4650.503761666063\n",
      "7366.310143681267\n",
      "11668.09617060963\n",
      "\n",
      "Table of bin edges:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lower Amp</th>\n",
       "      <th>Upper Amp</th>\n",
       "      <th>Lower Bin Diameter</th>\n",
       "      <th>Upper Bin Diameter</th>\n",
       "      <th>Mean Diameter (nm)</th>\n",
       "      <th>Bin Header</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.430191</td>\n",
       "      <td>11.769283</td>\n",
       "      <td>120.025342</td>\n",
       "      <td>130.818086</td>\n",
       "      <td>125.421714</td>\n",
       "      <td>120.03_130.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.769283</td>\n",
       "      <td>18.642322</td>\n",
       "      <td>130.818086</td>\n",
       "      <td>143.198798</td>\n",
       "      <td>137.008442</td>\n",
       "      <td>130.82_143.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.642322</td>\n",
       "      <td>29.529086</td>\n",
       "      <td>143.198798</td>\n",
       "      <td>157.782008</td>\n",
       "      <td>150.490403</td>\n",
       "      <td>143.2_157.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.529086</td>\n",
       "      <td>46.773514</td>\n",
       "      <td>157.782008</td>\n",
       "      <td>175.575915</td>\n",
       "      <td>166.678962</td>\n",
       "      <td>157.78_175.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46.773514</td>\n",
       "      <td>74.088363</td>\n",
       "      <td>175.575915</td>\n",
       "      <td>198.075846</td>\n",
       "      <td>186.825881</td>\n",
       "      <td>175.58_198.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>74.088363</td>\n",
       "      <td>117.354568</td>\n",
       "      <td>198.075846</td>\n",
       "      <td>227.168410</td>\n",
       "      <td>212.622128</td>\n",
       "      <td>198.08_227.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>117.354568</td>\n",
       "      <td>185.887420</td>\n",
       "      <td>227.168410</td>\n",
       "      <td>270.145591</td>\n",
       "      <td>248.657000</td>\n",
       "      <td>227.17_270.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>185.887420</td>\n",
       "      <td>294.442163</td>\n",
       "      <td>270.145591</td>\n",
       "      <td>351.087673</td>\n",
       "      <td>310.616632</td>\n",
       "      <td>270.15_351.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>294.442163</td>\n",
       "      <td>466.390827</td>\n",
       "      <td>351.087673</td>\n",
       "      <td>479.997437</td>\n",
       "      <td>415.542555</td>\n",
       "      <td>351.09_480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>466.390827</td>\n",
       "      <td>738.754263</td>\n",
       "      <td>479.997437</td>\n",
       "      <td>576.977273</td>\n",
       "      <td>528.487355</td>\n",
       "      <td>480.0_576.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>738.754263</td>\n",
       "      <td>1170.172803</td>\n",
       "      <td>576.977273</td>\n",
       "      <td>687.598795</td>\n",
       "      <td>632.288034</td>\n",
       "      <td>576.98_687.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1170.172803</td>\n",
       "      <td>1853.531623</td>\n",
       "      <td>687.598795</td>\n",
       "      <td>905.175145</td>\n",
       "      <td>796.386970</td>\n",
       "      <td>687.6_905.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1853.531623</td>\n",
       "      <td>2935.959092</td>\n",
       "      <td>905.175145</td>\n",
       "      <td>1193.713863</td>\n",
       "      <td>1049.444504</td>\n",
       "      <td>905.18_1193.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2935.959092</td>\n",
       "      <td>4650.503762</td>\n",
       "      <td>1193.713863</td>\n",
       "      <td>1720.624721</td>\n",
       "      <td>1457.169292</td>\n",
       "      <td>1193.71_1720.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4650.503762</td>\n",
       "      <td>7366.310144</td>\n",
       "      <td>1720.624721</td>\n",
       "      <td>2324.798664</td>\n",
       "      <td>2022.711693</td>\n",
       "      <td>1720.62_2324.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7366.310144</td>\n",
       "      <td>11668.096171</td>\n",
       "      <td>2324.798664</td>\n",
       "      <td>3000.027122</td>\n",
       "      <td>2662.412893</td>\n",
       "      <td>2324.8_3000.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Lower Amp     Upper Amp  Lower Bin Diameter  Upper Bin Diameter   \n",
       "0      7.430191     11.769283          120.025342          130.818086  \\\n",
       "1     11.769283     18.642322          130.818086          143.198798   \n",
       "2     18.642322     29.529086          143.198798          157.782008   \n",
       "3     29.529086     46.773514          157.782008          175.575915   \n",
       "4     46.773514     74.088363          175.575915          198.075846   \n",
       "5     74.088363    117.354568          198.075846          227.168410   \n",
       "6    117.354568    185.887420          227.168410          270.145591   \n",
       "7    185.887420    294.442163          270.145591          351.087673   \n",
       "8    294.442163    466.390827          351.087673          479.997437   \n",
       "9    466.390827    738.754263          479.997437          576.977273   \n",
       "10   738.754263   1170.172803          576.977273          687.598795   \n",
       "11  1170.172803   1853.531623          687.598795          905.175145   \n",
       "12  1853.531623   2935.959092          905.175145         1193.713863   \n",
       "13  2935.959092   4650.503762         1193.713863         1720.624721   \n",
       "14  4650.503762   7366.310144         1720.624721         2324.798664   \n",
       "15  7366.310144  11668.096171         2324.798664         3000.027122   \n",
       "\n",
       "    Mean Diameter (nm)       Bin Header  \n",
       "0           125.421714    120.03_130.82  \n",
       "1           137.008442     130.82_143.2  \n",
       "2           150.490403     143.2_157.78  \n",
       "3           166.678962    157.78_175.58  \n",
       "4           186.825881    175.58_198.08  \n",
       "5           212.622128    198.08_227.17  \n",
       "6           248.657000    227.17_270.15  \n",
       "7           310.616632    270.15_351.09  \n",
       "8           415.542555     351.09_480.0  \n",
       "9           528.487355     480.0_576.98  \n",
       "10          632.288034     576.98_687.6  \n",
       "11          796.386970     687.6_905.18  \n",
       "12         1049.444504   905.18_1193.71  \n",
       "13         1457.169292  1193.71_1720.62  \n",
       "14         2022.711693   1720.62_2324.8  \n",
       "15         2662.412893   2324.8_3000.03  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Produce mie table dataframe\n",
    "mie_conv_table = pd.read_csv(mie_input_csv)\n",
    "table_amp = mie_conv_table['amp_scale']\n",
    "table_diam = mie_conv_table['d_nm']\n",
    "mie_table = create_bins(num_bins,logmin,logmax,table_amp, table_diam, False)\n",
    "mie_table.to_csv(working_dir+\"/resulting_mie-table.csv\") ### binning check!\n",
    "bins = (list(mie_table['Lower Amp'])\n",
    "+ list(mie_table['Upper Amp'][-1:]))\n",
    "\n",
    "# Display calculated information\n",
    "print('list of bin edges reported as raw intensities:')\n",
    "print(*bins, sep = \"\\n\")\n",
    "print('\\nTable of bin edges:')\n",
    "mie_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordered list of binary files:\n",
      "./Example_data/POPS_F20230707/Peak_20230707x001.b\n",
      "./Example_data/POPS_F20230707/Peak_20230707x002.b\n",
      "./Example_data/POPS_F20230707/Peak_20230707x003.b\n",
      "./Example_data/POPS_F20230707/Peak_20230707x004.b\n",
      "./Example_data/POPS_F20230707/Peak_20230707x005.b\n",
      "./Example_data/POPS_F20230707/Peak_20230707x006.b\n",
      "./Example_data/POPS_F20230707/Peak_20230707x007.b\n",
      "./Example_data/POPS_F20230707/Peak_20230707x008.b\n",
      "./Example_data/POPS_F20230707/Peak_20230707x009.b\n"
     ]
    }
   ],
   "source": [
    " ### Walk subdirectories for all binary files ###\n",
    "source_directory = working_dir\n",
    "# create list of binary files with complete path included\n",
    "binary_files_2_process = []\n",
    "for dirpath, dirnames, filenames in os.walk(source_directory):\n",
    "    for filename in [f for f in filenames if f.endswith(\".b\")]:\n",
    "        full_path = os.path.join(dirpath, filename)\n",
    "        binary_files_2_process.append(full_path)\n",
    "binary_files_2_process.sort(key=os.path.getmtime)\n",
    "\n",
    "# Display calculated information\n",
    "print('Ordered list of binary files:')\n",
    "print(*binary_files_2_process, sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created ./Example_data/POPS_F20230707/Peak_20230707x001_10Hz.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1/9 [00:09<01:18,  9.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created ./Example_data/POPS_F20230707/Peak_20230707x002_10Hz.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2/9 [00:09<00:28,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created ./Example_data/POPS_F20230707/Peak_20230707x003_10Hz.csv\n",
      "created ./Example_data/POPS_F20230707/Peak_20230707x004_10Hz.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4/9 [00:17<00:18,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created ./Example_data/POPS_F20230707/Peak_20230707x005_10Hz.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5/9 [00:20<00:15,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created ./Example_data/POPS_F20230707/Peak_20230707x006_10Hz.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6/9 [00:26<00:13,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created ./Example_data/POPS_F20230707/Peak_20230707x007_10Hz.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7/9 [00:26<00:06,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created ./Example_data/POPS_F20230707/Peak_20230707x008_10Hz.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 8/9 [01:59<00:30, 30.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created ./Example_data/POPS_F20230707/Peak_20230707x009_10Hz.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [02:22<00:00, 15.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run on multiple processors (idk if this will work on jupyter)\n",
    "binary_mie_bins = [(f, mie_table, bins) for f in binary_files_2_process] # a single argument is needed for pool\n",
    "\n",
    "### Perform extraction is pools of 4 (four processes at once) ###\n",
    "# do not run the multiprocessing section, Keep run_multiprocessing = False\n",
    "if run_multiprocessing == True:\n",
    "    print('Multiprocessing enabled... 4 procs being used.')\n",
    "    p = Pool(4)\n",
    "    p.map(binary_2_csv,binary_mie_bins)\n",
    "\n",
    "### run the binary extraction and binning code on each binary file\n",
    "else:\n",
    "    for group in tqdm(binary_mie_bins):\n",
    "        try:\n",
    "            raw_peak_df, df_10Hz, bin_counts = binary_2_csv(group)\n",
    "        except Exception as e:\n",
    "            print(\"File Error!\")\n",
    "            print(\"{} failed\".format(group))\n",
    "            print(\"error:\\n\", e)\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A look into the bin creation steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>Peaks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-07 21:36:09.998292</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-07-07 21:36:09.998303</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-07-07 21:36:09.998313</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-07-07 21:36:09.998325</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-07-07 21:36:09.998329</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287092</th>\n",
       "      <td>2023-07-07 21:55:19.215172</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287093</th>\n",
       "      <td>2023-07-07 21:55:19.216175</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287094</th>\n",
       "      <td>2023-07-07 21:55:19.216960</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287095</th>\n",
       "      <td>2023-07-07 21:55:19.229364</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287096</th>\n",
       "      <td>2023-07-07 21:55:19.241996</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>287097 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        timestamp  Peaks\n",
       "0      2023-07-07 21:36:09.998292     71\n",
       "1      2023-07-07 21:36:09.998303     94\n",
       "2      2023-07-07 21:36:09.998313     83\n",
       "3      2023-07-07 21:36:09.998325     79\n",
       "4      2023-07-07 21:36:09.998329     83\n",
       "...                           ...    ...\n",
       "287092 2023-07-07 21:55:19.215172     80\n",
       "287093 2023-07-07 21:55:19.216175    106\n",
       "287094 2023-07-07 21:55:19.216960    177\n",
       "287095 2023-07-07 21:55:19.229364    188\n",
       "287096 2023-07-07 21:55:19.241996    102\n",
       "\n",
       "[287097 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP1: The raw data frame generated from decoding the binary files\n",
    "raw_peak_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp\n",
       "2023-07-07 21:36:09.900     [71, 94, 83, 79, 83, 100, 76, 109, 78, 110, 342]\n",
       "2023-07-07 21:36:10.000    [135, 175, 303, 77, 655, 569, 270, 126, 266, 1...\n",
       "2023-07-07 21:36:10.100    [1037, 103, 180, 177, 113, 1273, 335, 116, 663...\n",
       "2023-07-07 21:36:10.200    [186, 641, 115, 129, 88, 941, 728, 94, 210, 10...\n",
       "2023-07-07 21:36:10.300    [679, 195, 271, 861, 108, 106, 217, 239, 159, ...\n",
       "                                                 ...                        \n",
       "2023-07-07 21:55:18.800    [244, 263, 187, 190, 310, 799, 133, 500, 448, ...\n",
       "2023-07-07 21:55:18.900    [116, 818, 105, 228, 287, 155, 490, 1136, 283,...\n",
       "2023-07-07 21:55:19.000    [454, 294, 127, 749, 814, 796, 108, 282, 566, ...\n",
       "2023-07-07 21:55:19.100    [114, 182, 231, 167, 737, 341, 332, 154, 476, ...\n",
       "2023-07-07 21:55:19.200              [731, 140, 325, 80, 106, 177, 188, 102]\n",
       "Freq: 100L, Name: Peaks, Length: 11494, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP2:10 Hz grouped peak data\n",
    "df_10Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Bin Header</th>\n",
       "      <th>120.03_130.82</th>\n",
       "      <th>130.82_143.2</th>\n",
       "      <th>143.2_157.78</th>\n",
       "      <th>157.78_175.58</th>\n",
       "      <th>175.58_198.08</th>\n",
       "      <th>198.08_227.17</th>\n",
       "      <th>227.17_270.15</th>\n",
       "      <th>270.15_351.09</th>\n",
       "      <th>351.09_480.0</th>\n",
       "      <th>480.0_576.98</th>\n",
       "      <th>576.98_687.6</th>\n",
       "      <th>687.6_905.18</th>\n",
       "      <th>905.18_1193.71</th>\n",
       "      <th>1193.71_1720.62</th>\n",
       "      <th>1720.62_2324.8</th>\n",
       "      <th>2324.8_3000.03</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-07-07 21:36:09.900</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-07 21:36:10.000</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-07 21:36:10.100</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-07 21:36:10.200</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-07 21:36:10.300</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-07 21:55:18.800</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-07 21:55:18.900</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-07 21:55:19.000</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-07 21:55:19.100</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-07 21:55:19.200</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11494 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Bin Header               120.03_130.82  130.82_143.2  143.2_157.78   \n",
       "timestamp                                                            \n",
       "2023-07-07 21:36:09.900              0             0             0  \\\n",
       "2023-07-07 21:36:10.000              0             0             0   \n",
       "2023-07-07 21:36:10.100              0             0             0   \n",
       "2023-07-07 21:36:10.200              0             0             0   \n",
       "2023-07-07 21:36:10.300              0             0             0   \n",
       "...                                ...           ...           ...   \n",
       "2023-07-07 21:55:18.800              0             0             0   \n",
       "2023-07-07 21:55:18.900              0             0             0   \n",
       "2023-07-07 21:55:19.000              0             0             0   \n",
       "2023-07-07 21:55:19.100              0             0             0   \n",
       "2023-07-07 21:55:19.200              0             0             0   \n",
       "\n",
       "Bin Header               157.78_175.58  175.58_198.08  198.08_227.17   \n",
       "timestamp                                                              \n",
       "2023-07-07 21:36:09.900              0              1              9  \\\n",
       "2023-07-07 21:36:10.000              0              0              5   \n",
       "2023-07-07 21:36:10.100              0              0              5   \n",
       "2023-07-07 21:36:10.200              0              0              8   \n",
       "2023-07-07 21:36:10.300              0              0              5   \n",
       "...                                ...            ...            ...   \n",
       "2023-07-07 21:55:18.800              0              1              6   \n",
       "2023-07-07 21:55:18.900              0              0              4   \n",
       "2023-07-07 21:55:19.000              0              1              7   \n",
       "2023-07-07 21:55:19.100              0              0              7   \n",
       "2023-07-07 21:55:19.200              0              0              3   \n",
       "\n",
       "Bin Header               227.17_270.15  270.15_351.09  351.09_480.0   \n",
       "timestamp                                                             \n",
       "2023-07-07 21:36:09.900              0              0             1  \\\n",
       "2023-07-07 21:36:10.000              5              4             4   \n",
       "2023-07-07 21:36:10.100              5              8             5   \n",
       "2023-07-07 21:36:10.200              7              8             6   \n",
       "2023-07-07 21:36:10.300              6             10             5   \n",
       "...                                ...            ...           ...   \n",
       "2023-07-07 21:55:18.800              5              5             6   \n",
       "2023-07-07 21:55:18.900              2              5             3   \n",
       "2023-07-07 21:55:19.000              4             10             5   \n",
       "2023-07-07 21:55:19.100             10              3             2   \n",
       "2023-07-07 21:55:19.200              2              1             1   \n",
       "\n",
       "Bin Header               480.0_576.98  576.98_687.6  687.6_905.18   \n",
       "timestamp                                                           \n",
       "2023-07-07 21:36:09.900             0             0             0  \\\n",
       "2023-07-07 21:36:10.000             3             0             0   \n",
       "2023-07-07 21:36:10.100             3             4             1   \n",
       "2023-07-07 21:36:10.200             8             4             0   \n",
       "2023-07-07 21:36:10.300             3             3             1   \n",
       "...                               ...           ...           ...   \n",
       "2023-07-07 21:55:18.800             6             7             0   \n",
       "2023-07-07 21:55:18.900             3             3             0   \n",
       "2023-07-07 21:55:19.000             4             5             0   \n",
       "2023-07-07 21:55:19.100             3             3             1   \n",
       "2023-07-07 21:55:19.200             1             0             0   \n",
       "\n",
       "Bin Header               905.18_1193.71  1193.71_1720.62  1720.62_2324.8   \n",
       "timestamp                                                                  \n",
       "2023-07-07 21:36:09.900               0                0               0  \\\n",
       "2023-07-07 21:36:10.000               0                0               0   \n",
       "2023-07-07 21:36:10.100               0                0               0   \n",
       "2023-07-07 21:36:10.200               0                0               0   \n",
       "2023-07-07 21:36:10.300               0                0               0   \n",
       "...                                 ...              ...             ...   \n",
       "2023-07-07 21:55:18.800               0                0               0   \n",
       "2023-07-07 21:55:18.900               1                0               0   \n",
       "2023-07-07 21:55:19.000               0                0               0   \n",
       "2023-07-07 21:55:19.100               0                0               0   \n",
       "2023-07-07 21:55:19.200               0                0               0   \n",
       "\n",
       "Bin Header               2324.8_3000.03  \n",
       "timestamp                                \n",
       "2023-07-07 21:36:09.900               0  \n",
       "2023-07-07 21:36:10.000               0  \n",
       "2023-07-07 21:36:10.100               0  \n",
       "2023-07-07 21:36:10.200               0  \n",
       "2023-07-07 21:36:10.300               0  \n",
       "...                                 ...  \n",
       "2023-07-07 21:55:18.800               0  \n",
       "2023-07-07 21:55:18.900               0  \n",
       "2023-07-07 21:55:19.000               0  \n",
       "2023-07-07 21:55:19.100               0  \n",
       "2023-07-07 21:55:19.200               0  \n",
       "\n",
       "[11494 rows x 16 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#STEP3: binned data\n",
    "bin_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
